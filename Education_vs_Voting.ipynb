{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNYdi2SWCUHb4W9A2BWw7LW"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# !pip install pyscipopt==4.3.0 --extra-index-url https://zenodo.org/api/files/kotdvw5srpqto3xslzj1\n",
        "\n",
        "!pip install git+https://github.com/duarteguilherme/autobounds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4MRdoRvWWyZM",
        "outputId": "f57d07e1-f746-45c9-87ac-f604f1b59bc0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/duarteguilherme/autobounds\n",
            "  Cloning https://github.com/duarteguilherme/autobounds to /tmp/pip-req-build-e_q0ml09\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/duarteguilherme/autobounds /tmp/pip-req-build-e_q0ml09\n",
            "  Resolved https://github.com/duarteguilherme/autobounds to commit 13b7520febdfe59d29c917a4501e69fde5f78c6d\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from autobounds==0.0.2) (4.67.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from autobounds==0.0.2) (2.2.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from autobounds==0.0.2) (3.6)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from autobounds==0.0.2) (3.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from autobounds==0.0.2) (2.0.2)\n",
            "Requirement already satisfied: plotnine in /usr/local/lib/python3.12/dist-packages (from autobounds==0.0.2) (0.14.5)\n",
            "Collecting pyscipopt (from autobounds==0.0.2)\n",
            "  Downloading pyscipopt-6.0.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from autobounds==0.0.2) (1.14.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from autobounds==0.0.2) (1.16.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->autobounds==0.0.2) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->autobounds==0.0.2) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->autobounds==0.0.2) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->autobounds==0.0.2) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->autobounds==0.0.2) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->autobounds==0.0.2) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->autobounds==0.0.2) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->autobounds==0.0.2) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->autobounds==0.0.2) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->autobounds==0.0.2) (2025.2)\n",
            "Requirement already satisfied: mizani~=0.13.0 in /usr/local/lib/python3.12/dist-packages (from plotnine->autobounds==0.0.2) (0.13.5)\n",
            "Requirement already satisfied: statsmodels>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from plotnine->autobounds==0.0.2) (0.14.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->autobounds==0.0.2) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib->autobounds==0.0.2) (1.17.0)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.12/dist-packages (from statsmodels>=0.14.0->plotnine->autobounds==0.0.2) (1.0.2)\n",
            "Downloading pyscipopt-6.0.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (17.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.2/17.2 MB\u001b[0m \u001b[31m72.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: autobounds\n",
            "  Building wheel for autobounds (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for autobounds: filename=autobounds-0.0.2-py3-none-any.whl size=45653 sha256=ee673ef2608772d9360bc43ec1434851cb6b91309b9153a581f1b9e5cd5aacdd\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-31htix_m/wheels/f6/97/98/02f08e322cbffa7a86cce247d08e3725715e8523ea5cf792e8\n",
            "Successfully built autobounds\n",
            "Installing collected packages: pyscipopt, autobounds\n",
            "Successfully installed autobounds-0.0.2 pyscipopt-6.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Autobound simulation"
      ],
      "metadata": {
        "id": "LVLrg9_Z8iaJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from autobounds import *\n",
        "import pandas\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "7v6RKerq4wRo"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "RsLCIYnpWQ0b"
      },
      "outputs": [],
      "source": [
        "confounding_model = DAG(\"D -> Y, X -> D, X -> Y, U -> D, U -> Y\", unob=\"U\")\n",
        "confounding_problem = causalProblem(confounding_model)\n",
        "confounding_problem.set_ate(ind=\"D\", dep=\"Y\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------------------------------------------------\n",
        "strata_list = [\n",
        "    (\"00\", \"0000\", 0.074576212961429),\n",
        "    (\"01\", \"0001\", 0.0301702777607751),\n",
        "    (\"01\", \"0101\", 0.186607173274612),\n",
        "    (\"01\", \"1101\", 0.00798467737923486),\n",
        "    (\"10\", \"0010\", 0.348297597134471),\n",
        "    (\"10\", \"1001\", 0.134412818663854),\n",
        "    (\"10\", \"1010\", 0.0480346194425266),\n",
        "    (\"10\", \"1111\", 0.0940165222917155),\n",
        "    (\"11\", \"1100\", 0.0345830964246296),\n",
        "    (\"11\", \"1101\", 0.041317004666752),\n",
        "]\n",
        "\n",
        "df = pandas.DataFrame(strata_list, columns=[\"D_type\", \"Y_type\", \"prob\"])\n",
        "\n",
        "N = 10000   # simulation size\n",
        "\n",
        "# sample D and Y according to the strata list\n",
        "stratum_idx = np.random.choice(df.index, size=N, p=df[\"prob\"].values)\n",
        "sim = df.loc[stratum_idx].reset_index(drop=True)\n",
        "\n",
        "# sample X ~ Bernoulli(0.6)\n",
        "sim[\"X\"] = np.random.binomial(1, 0.6, size=N)\n",
        "\n",
        "# compute factual D and Y based on principal strata definitions\n",
        "def compute_D(D_type, X):\n",
        "    # D_type = d0d1\n",
        "    return int(D_type[X])\n",
        "\n",
        "def compute_Y(Y_type, D, X):\n",
        "    # Y_type = y00 y01 y10 y11  (4 bits)\n",
        "    # index = 2*D + X\n",
        "    idx = 2 * D + X\n",
        "    return int(Y_type[idx])\n",
        "\n",
        "# factual D\n",
        "sim[\"D\"] = [compute_D(dt, x) for dt, x in zip(sim[\"D_type\"], sim[\"X\"])]\n",
        "\n",
        "# factual Y\n",
        "sim[\"Y\"] = [compute_Y(yt, d, x)\n",
        "            for yt, d, x in zip(sim[\"Y_type\"], sim[\"D\"], sim[\"X\"])]\n",
        "\n",
        "# store factual observed data\n",
        "confounding_data = sim[[\"X\", \"D\", \"Y\"]]"
      ],
      "metadata": {
        "id": "85Ff5_9A3WBs"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# solve without monotone response constraints\n",
        "confounding_problem.read_data(raw=confounding_data, inference=True)\n",
        "confounding_problem.solve(ci=True, nsamples=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xo9PPuc7r93V",
        "outputId": "b93d070e-9cdf-45a5-a556-4e0ee1f28f9a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Solving for point estimate bounds...\n",
            "Point estimates\n",
            "\n",
            "Dual: [-0.1659, 0.8341]\n",
            "Primal: [-0.1659, 0.8341]\n",
            "Generating samples:\n",
            "\n",
            "Estimating CI: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:07<00:00,  1.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "95% Confidence intervals. Lower: -0.1719595772592103,  Upper: 0.8355688151499093\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'point lb dual': -0.1659,\n",
              " 'point ub dual': 0.8341,\n",
              " 'point lb primal': -0.1659,\n",
              " 'point ub primal': 0.8341,\n",
              " '2.5% lb bounds': np.float64(-0.1719595772592103),\n",
              " '97.5% ub bounds': np.float64(0.8355688151499093),\n",
              " '1% lb bounds': np.float64(-0.1721159266440455),\n",
              " '99% ub bounds': np.float64(0.8356221828684943)}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "confounding_problem.read_data(raw=confounding_data.iloc[:1000], inference=True)\n",
        "\n",
        "# add monotone-response assumptions (E[Y(d)|X=1] >= E[Y(d)|X=0] for d=0,1)\n",
        "with respect_to(confounding_problem):\n",
        "    turnout_if_college_in_highSES = E(\"Y(D=1)\", cond=\"X=1\")\n",
        "    turnout_if_college_in_lowSES  = E(\"Y(D=1)\", cond=\"X=0\")\n",
        "    turnout_if_nocollege_in_highSES = E(\"Y(D=0)\", cond=\"X=1\")\n",
        "    turnout_if_nocollege_in_lowSES  = E(\"Y(D=0)\", cond=\"X=0\")\n",
        "\n",
        "    add_assumption(turnout_if_college_in_highSES, '>=', turnout_if_college_in_lowSES)\n",
        "    add_assumption(turnout_if_nocollege_in_highSES, '>=', turnout_if_nocollege_in_lowSES)\n",
        "\n",
        "# solve LP and request inferential sampling\n",
        "confounding_problem.solve(ci=True, nsamples=10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vLNZgKB9G8tJ",
        "outputId": "653719bf-b00d-4f16-e48f-57099bd77566"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Solving for point estimate bounds...\n",
            "Point estimates\n",
            "\n",
            "Dual: [0.100920326932022, 0.828]\n",
            "Primal: [0.100920326932022, 0.828]\n",
            "Generating samples:\n",
            "\n",
            "Estimating CI: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:06<00:00,  1.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "95% Confidence intervals. Lower: 0.04870077558369033,  Upper: 0.8373640605896486\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'point lb dual': 0.100920326932022,\n",
              " 'point ub dual': 0.828,\n",
              " 'point lb primal': 0.100920326932022,\n",
              " 'point ub primal': 0.828,\n",
              " '2.5% lb bounds': np.float64(0.04870077558369033),\n",
              " '97.5% ub bounds': np.float64(0.8373640605896486),\n",
              " '1% lb bounds': np.float64(0.04855540791709363),\n",
              " '99% ub bounds': np.float64(0.8376593582976131)}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optimize only via the primal"
      ],
      "metadata": {
        "id": "vpjC2dOv8qtG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "\n",
        "class ATEPrimalSolver:\n",
        "    \"\"\"\n",
        "    Solves the primal linear program with gradient descent.\n",
        "    Decision variables: p[x,d,y0,y1] for x,d,y0,y1 in {0,1}\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, X, D, Y):\n",
        "        \"\"\"\n",
        "        X, D, Y are numpy arrays of observed data\n",
        "        \"\"\"\n",
        "        self.X = X\n",
        "        self.D = D\n",
        "        self.Y = Y\n",
        "\n",
        "        # empirical joint P_obs(X=x, D=d, Y=y)\n",
        "        self.q_obs = self._compute_observed_joint()\n",
        "\n",
        "        # empirical marginal\n",
        "        self.px = np.array([np.mean(X == 0), np.mean(X == 1)])\n",
        "\n",
        "        # create trainable probabilities (16 variables)\n",
        "        self.p = torch.nn.Parameter(\n",
        "            torch.ones(2,2,2,2, dtype=torch.double) / 16,\n",
        "            requires_grad=True\n",
        "        )\n",
        "\n",
        "        self.optimizer = torch.optim.Adam([self.p], lr=5e-2)\n",
        "\n",
        "    # -----------------------------------------------------------\n",
        "    def _compute_observed_joint(self):\n",
        "        q = np.zeros((2,2,2))\n",
        "        N = len(self.X)\n",
        "        for x,d,y in zip(self.X, self.D, self.Y):\n",
        "            q[x,d,y] += 1\n",
        "        return q / N\n",
        "\n",
        "    # -----------------------------------------------------------\n",
        "    def _objective(self, maximize=False):\n",
        "        \"\"\"\n",
        "        ATE = sum (y1 - y0) * p\n",
        "        \"\"\"\n",
        "        y0 = torch.arange(2, dtype=torch.double)\n",
        "        y1 = torch.arange(2, dtype=torch.double)\n",
        "        Y0, Y1 = torch.meshgrid(y0, y1, indexing='ij')\n",
        "\n",
        "        ATE = torch.sum((Y1 - Y0)[None,None,:,:] * self.p)\n",
        "\n",
        "        return -ATE if maximize else ATE\n",
        "\n",
        "    # -----------------------------------------------------------\n",
        "    def _constraints_loss(self):\n",
        "        loss = 0.0\n",
        "\n",
        "        # (C1) observed joint constraints: sum_{y0,y1: y_d=y} p = q_obs\n",
        "        for x in [0,1]:\n",
        "            for d in [0,1]:\n",
        "                for y in [0,1]:\n",
        "                    mask = torch.zeros((2,2))\n",
        "                    for y0 in [0,1]:\n",
        "                        for y1 in [0,1]:\n",
        "                            yd = y1 if d==1 else y0\n",
        "                            if yd == y:\n",
        "                                mask[y0,y1] = 1\n",
        "                    loss += (torch.sum(self.p[x,d] * mask) - self.q_obs[x,d,y])**2\n",
        "\n",
        "        # (C2) normalization\n",
        "        loss += (torch.sum(self.p) - 1.0)**2\n",
        "\n",
        "        # (C3) monotone-response:\n",
        "        # E[Y(d)|X=1] >= E[Y(d)|X=0]\n",
        "        for d in [0,1]:\n",
        "            # LHS = p0 * E[Y(d)|X=1] - p1 * E[Y(d)|X=0]\n",
        "            E1 = 0.0\n",
        "            E0 = 0.0\n",
        "            for d2 in [0,1]:\n",
        "                for y0 in [0,1]:\n",
        "                    for y1 in [0,1]:\n",
        "                        yd = y1 if d==1 else y0\n",
        "                        E1 += yd * self.p[1,d2,y0,y1]\n",
        "                        E0 += yd * self.p[0,d2,y0,y1]\n",
        "\n",
        "            lhs = self.px[0] * E1 - self.px[1] * E0\n",
        "            loss += torch.relu(-lhs)   # penalty only if violated\n",
        "\n",
        "        # (C2b) nonnegativity\n",
        "        loss += torch.sum(torch.relu(-self.p))\n",
        "\n",
        "        return loss\n",
        "\n",
        "    # -----------------------------------------------------------\n",
        "    def solve(self, maximize=False, iters=6000, l_constrained = 10):\n",
        "        for it in range(iters):\n",
        "            self.optimizer.zero_grad()\n",
        "            loss = self._objective(maximize=maximize) + l_constrained * self._constraints_loss()\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "\n",
        "            # project to >=0 to keep stable\n",
        "            with torch.no_grad():\n",
        "                self.p.data.clamp_(min=1e-9)\n",
        "                # renormalize to keep mass ~1\n",
        "                self.p.data /= self.p.data.sum()\n",
        "\n",
        "        ATE_est = -self._objective(maximize=maximize).item() if maximize else self._objective().item()\n",
        "        return ATE_est, self.p.data.clone()\n",
        "\n",
        "# return upper and lower bounds\n",
        "def solve_ATE_bounds(confounding_data, iters=6000):\n",
        "    X = confounding_data[\"X\"].values\n",
        "    D = confounding_data[\"D\"].values\n",
        "    Y = confounding_data[\"Y\"].values\n",
        "\n",
        "    solver = ATEPrimalSolver(X, D, Y)\n",
        "\n",
        "    lb, p_min = solver.solve(maximize=False, iters=iters, l_constrained=100)\n",
        "    ub, p_max = solver.solve(maximize=True,  iters=iters, l_constrained=100)\n",
        "\n",
        "    return {\n",
        "        \"ATE_lower\": lb,\n",
        "        \"ATE_upper\": ub,\n",
        "        \"p_min_solution\": p_min,\n",
        "        \"p_max_solution\": p_max,\n",
        "    }"
      ],
      "metadata": {
        "id": "N2j-13UEdhxW"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = solve_ATE_bounds(confounding_data, iters=8000)\n",
        "\n",
        "print(\"ATE lower bound =\", result[\"ATE_lower\"])\n",
        "print(\"ATE upper bound =\", result[\"ATE_upper\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M-aRpGESeuPN",
        "outputId": "c389d2fa-616f-4fdb-9a59-2b0b69eb65ce"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ATE lower bound = 0.13000004948273106\n",
            "ATE upper bound = 0.7259100321970758\n"
          ]
        }
      ]
    }
  ]
}